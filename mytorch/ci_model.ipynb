{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amir Kabir University of technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Intelligence - Project 1 - 9931xx6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tensor import Tensor\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#don't change this cell\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not change this cell\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self.data = pd.get_dummies(pd.read_csv(path), columns=['Species']).astype(float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.data.iloc[idx]\n",
    "        features = torch.tensor(row[:-3].values, dtype=torch.float32)\n",
    "        label = torch.tensor([row.iloc[-3],row.iloc[-2],row.iloc[-1]], dtype=torch.float32)\n",
    "        return features, label\n",
    "\n",
    "    @property\n",
    "    def classes(parameter_list):\n",
    "        return ['Iris-setosa','Iris-versicolor','Iris-virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_path = os.getcwd()\n",
    "\n",
    "#TODO change pathes\n",
    "path_train = os.path.join(base_path, \"Iris-Train.csv\")\n",
    "path_test = os.path.join(base_path, \"Iris-Test.csv\")\n",
    "\n",
    "dataset_train = CSVDataset(path_train)\n",
    "dataset_test = CSVDataset(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#TODO set parameters\n",
    "loader_train = DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=10,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "loader_test = DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    batch_size=10,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   size\t= 10\n",
      "train   size\t= 105\n",
      "test    size\t= 60\n",
      "Class   names\t= ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
      "input   shape\t= torch.Size([4])\n",
      "output  shape\t= torch.Size([3])\n",
      "example input\t= tensor([5.1000, 3.5000, 1.4000, 0.2000])\n",
      "example output\t= tensor([1., 0., 0.])\n",
      "example label\t= Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "#don't change this cell\n",
    "print(f\"batch   size\\t= {loader_train.batch_size}\")\n",
    "print(f\"train   size\\t= {len(dataset_train):,}\")\n",
    "print(f\"test    size\\t= {len(dataset_test):,}\")\n",
    "print(f\"Class   names\\t= {dataset_train.classes}\")\n",
    "print(f\"input   shape\\t= {dataset_train[0][0].shape}\")\n",
    "print(f\"output  shape\\t= {dataset_train[0][1].shape}\")\n",
    "print(f\"example input\\t= {dataset_train[0][0]}\")\n",
    "print(f\"example output\\t= {dataset_train[0][1]}\")\n",
    "print(f\"example label\\t= {dataset_train.classes[dataset_train[0][1].argmax()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1:  linear - total param: 20 - in: 4, out: 5\n",
      "linear2:  linear - total param: 15 - in: 5, out: 3\n"
     ]
    }
   ],
   "source": [
    "from myModel import MyModel\n",
    "\n",
    "mymodel = MyModel()\n",
    "MyModel.summary(self=mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss.mse import MeanSquaredError\n",
    "from optimizer import SGD\n",
    "\n",
    "def one_epoch_learning(\n",
    "    model: MyModel,\n",
    "    criterion: MeanSquaredError,\n",
    "    loader: DataLoader,\n",
    "    optimizer: SGD,\n",
    ") -> int:\n",
    "    accs = 0\n",
    "    for data, label in loader:\n",
    "        data: Tensor = data.to(device)\n",
    "        label: Tensor = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        res: Tensor = model(data)\n",
    "        loss: Tensor = criterion(res, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        accs += (res.argmax(dim=1) == label.argmax(dim=1)).sum().item()\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't change this cell\n",
    "def calculate_accuracy(\n",
    "    model: MyModel, loader: DataLoader, criterion: MeanSquaredError\n",
    ") -> int:\n",
    "    model.eval()\n",
    "    accs = 0\n",
    "    for data, label in loader:\n",
    "        data: Tensor = data.to(device)\n",
    "        label: Tensor = label.to(device)\n",
    "\n",
    "        res: Tensor = model(data)\n",
    "\n",
    "        accs += (res.argmax(dim=1) == label.argmax(dim=1)).sum().item()\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: MyModel,\n",
    "    criterion: MeanSquaredError,\n",
    "    loader_train: DataLoader,\n",
    "    loader_test: DataLoader,\n",
    "    optimizer: SGD,\n",
    "    epoch: int,\n",
    "):\n",
    "    results_train = []\n",
    "    results_test = []\n",
    "    for i in tqdm(range(epoch)):\n",
    "        res_train = one_epoch_learning(model, criterion, loader_train, optimizer)\n",
    "        results_train.append(res_train / len(loader_train.dataset))\n",
    "        res_test = calculate_accuracy(model, loader_test, criterion)\n",
    "        results_test.append(res_test / len(loader_test.dataset))\n",
    "    return results_train, results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[0.         0.         3.45054944 3.88036634 2.39426558]\n",
      " [0.         0.         4.35972476 4.54506551 2.9507286 ]\n",
      " [0.         0.         3.19950863 3.54492573 2.18188187]\n",
      " [0.         0.         2.09196785 2.56349758 1.40217211]\n",
      " [0.         0.         2.93926827 3.39815855 2.03618272]\n",
      " [0.         0.         3.38183818 3.67007492 2.30012334]\n",
      " [0.         0.         3.39984386 3.4213491  2.2144315 ]\n",
      " [0.         0.         2.79304566 2.9826335  1.88242252]\n",
      " [0.         0.         3.56725777 4.16313335 2.50394769]\n",
      " [0.         0.         3.21934552 3.67791398 2.23549066]], requires_grad=True)\n",
      "(10, 5)\n",
      "Tensor([[8.55791160e-02 9.12817374e-01 1.60350966e-03]\n",
      " [6.69765690e-02 9.32367390e-01 6.56041370e-04]\n",
      " [1.04355240e-01 8.92851241e-01 2.79351848e-03]\n",
      " [1.57605385e-01 8.30908961e-01 1.14856540e-02]\n",
      " [1.07479764e-01 8.89224721e-01 3.29551474e-03]\n",
      " [1.00377370e-01 8.97247680e-01 2.37494986e-03]\n",
      " [1.24984383e-01 8.71055381e-01 3.96023590e-03]\n",
      " [1.45529695e-01 8.47480223e-01 6.99008240e-03]\n",
      " [6.91338438e-02 9.29909230e-01 9.56926482e-04]\n",
      " [9.36212731e-02 9.04224711e-01 2.15401539e-03]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'Tensor' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m SGD(mymodel\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[0;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m CategoricalCrossEntropy\n\u001b[1;32m----> 7\u001b[0m train_accs, test_accs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmymodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCH\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, criterion, loader_train, loader_test, optimizer, epoch)\u001b[0m\n\u001b[0;32m     10\u001b[0m results_test \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epoch)):\n\u001b[1;32m---> 12\u001b[0m     res_train \u001b[38;5;241m=\u001b[39m \u001b[43mone_epoch_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     results_train\u001b[38;5;241m.\u001b[39mappend(res_train \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader_train\u001b[38;5;241m.\u001b[39mdataset))\n\u001b[0;32m     14\u001b[0m     res_test \u001b[38;5;241m=\u001b[39m calculate_accuracy(model, loader_test, criterion)\n",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m, in \u001b[0;36mone_epoch_learning\u001b[1;34m(model, criterion, loader, optimizer)\u001b[0m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m res: Tensor \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m---> 17\u001b[0m loss: Tensor \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\wasiq\\OneDrive\\Desktop\\CI\\CI Projects\\Project1\\mytorch\\loss\\ce.py:38\u001b[0m, in \u001b[0;36mCategoricalCrossEntropy\u001b[1;34m(preds, label)\u001b[0m\n\u001b[0;32m     35\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m Tensor(\u001b[38;5;28mfloat\u001b[39m(preds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Return negative mean (since we want to minimize -log likelihood)\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlog_likelihood\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'Tensor' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "from loss import CategoricalCrossEntropy\n",
    "\n",
    "EPOCH = 1\n",
    "optimizer = SGD(mymodel.parameters())\n",
    "loss = CategoricalCrossEntropy\n",
    "\n",
    "train_accs, test_accs = train(mymodel, loss, loader_train, loader_test, optimizer, EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_accs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#don't change this cell\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_accs\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(test_accs, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_accs' is not defined"
     ]
    }
   ],
   "source": [
    "#don't change this cell\n",
    "plt.plot(train_accs, label=\"Train accuracy\")\n",
    "plt.plot(test_accs, label=\"Test accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final train acc = 0.97143\n",
      "final test acc = 0.93333\n",
      "max train acc = 0.97143\n",
      "max test acc = 0.93333\n",
      "min train acc = 0.69524\n",
      "min test acc = 0.68333\n"
     ]
    }
   ],
   "source": [
    "#don't change this cell\n",
    "print(f\"final train acc = {train_accs[-1]:.5f}\")\n",
    "print(f\"final test acc = {test_accs[-1]:.5f}\")\n",
    "print(f\"max train acc = {max(train_accs):.5f}\")\n",
    "print(f\"max test acc = {max(test_accs):.5f}\")\n",
    "print(f\"min train acc = {min(train_accs):.5f}\")\n",
    "print(f\"min test acc = {min(test_accs):.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "civenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
